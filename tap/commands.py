"""å‘½ä»¤æ¨¡å—"""

from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from .config import get_config
from .client import get_client
from .reader import get_reader


class CheckCommand:
    """æ ¡éªŒå‘½ä»¤"""
    
    def __init__(self, file_path: str, frozen_zone: str, data_zone: str, table_id: str):
        self.file_path = Path(file_path)
        self.frozen_zone = frozen_zone
        self.data_zone = data_zone
        self.table_id = table_id
        
        self.config = get_config()
        self.client = get_client(self.config)
        self.reader = get_reader(file_path, frozen_zone, data_zone)
    
    def run(self) -> bool:
        """æ‰§è¡Œæ ¡éªŒ"""
        try:
            # æ£€æŸ¥é…ç½®
            if not self.config.is_configured():
                raise Exception("è¯·å…ˆé…ç½®APP_IDå’ŒAPP_SECRET")
            
            if not self.config.app_token:
                raise Exception("è¯·å…ˆé…ç½®app_token")
            
            # è¯»å–æ–‡ä»¶è¡¨å¤´
            file_headers = self.reader.read_headers()
            frozen_headers = self.reader.read_frozen_headers()
            
            # è·å–é£ä¹¦è¡¨æ ¼å­—æ®µ
            bitable_fields = self.client.get_fields(self.config.app_token, self.table_id)
            bitable_field_names = {f.get("field_name") for f in bitable_fields}
            
            # æ ¡éªŒæ•°æ®åŒºåŸŸå­—æ®µ
            errors = []
            for i, header in enumerate(file_headers):
                # å…¼å®¹ExcelReaderå’ŒCSVReader
                data_start = getattr(self.reader, '_data_cols', getattr(self.reader, 'data_cols', (0, 0)))[0]
                col_letter = chr(ord('A') + i + data_start)
                if header and header not in bitable_field_names:
                    errors.append({
                        "type": "field_missing",
                        "location": f"{col_letter}1",
                        "field": header,
                        "message": f"å­—æ®µ '{header}' åœ¨æ•°æ®è¡¨ä¸­ä¸å­˜åœ¨"
                    })
            
            # æ ¡éªŒå†»ç»“åŒºåŸŸå­—æ®µï¼ˆç”¨äºæ•°æ®IDï¼‰
            for header in frozen_headers:
                if header and header not in bitable_field_names:
                    errors.append({
                        "type": "field_missing",
                        "location": f"å†»ç»“åŒºåŸŸ",
                        "field": header,
                        "message": f"å†»ç»“åŒºåŸŸå­—æ®µ '{header}' åœ¨æ•°æ®è¡¨ä¸­ä¸å­˜åœ¨"
                    })
            
            if errors:
                print("âŒ æ ¡éªŒå¤±è´¥ï¼Œå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n")
                for error in errors:
                    print(f"  [{error['type']}] {error['location']}: {error['message']}")
                return False
            else:
                print("âœ… æ ¡éªŒé€šè¿‡ï¼Œæ‰€æœ‰å­—æ®µéƒ½åŒ¹é…")
                return True
                
        except Exception as e:
            print(f"âŒ æ ¡éªŒå¤±è´¥: {e}")
            return False


class FlushCommand:
    """åŒæ­¥å‘½ä»¤"""
    
    def __init__(self, file_path: str, frozen_zone: str, data_zone: str, 
                 table_id: str, mode: str = "record"):
        self.file_path = Path(file_path)
        self.frozen_zone = frozen_zone
        self.data_zone = data_zone
        self.table_id = table_id
        self.mode = mode  # "field" or "record"
        
        self.config = get_config()
        self.client = get_client(self.config)
        self.reader = get_reader(file_path, frozen_zone, data_zone)
    
    def _generate_data_id(self, frozen_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®ID
        æ•°æ®ID = ä¼ä¸šID + _ + æ•°æ®é›† + ä¼šè®¡æœŸé—´ + æŠ¥è¡¨ç±»å‹
        """
        def to_str(value):
            """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
            if value is None:
                return ""
            if isinstance(value, list):
                return ",".join(str(v) for v in value)
            return str(value)
        
        enterprise_id = to_str(frozen_data.get("ä¼ä¸šID"))
        dataset = to_str(frozen_data.get("æ•°æ®é›†"))
        period = to_str(frozen_data.get("ä¼šè®¡æœŸé—´"))
        report_type = to_str(frozen_data.get("æŠ¥è¡¨ç±»å‹"))
        
        return f"{enterprise_id}_{dataset}{period}{report_type}"
    
    def run(self) -> Tuple[bool, Dict]:
        """æ‰§è¡ŒåŒæ­¥"""
        try:
            # æ£€æŸ¥é…ç½®
            if not self.config.is_configured():
                raise Exception("è¯·å…ˆé…ç½®APP_IDå’ŒAPP_SECRET")
            
            if not self.config.app_token:
                raise Exception("è¯·å…ˆé…ç½®app_token")
            
            # è¯»å–æ–‡ä»¶æ•°æ®
            frozen_headers = self.reader.read_frozen_headers()
            data_headers = self.reader.read_headers()
            frozen_data_list = self.reader.read_frozen_data()
            data_rows = self.reader.read_data()
            
            # è·å–é£ä¹¦è¡¨æ ¼å­—æ®µ
            bitable_fields = self.client.get_fields(self.config.app_token, self.table_id)
            bitable_field_map = {f.get("field_name"): f for f in bitable_fields}
            
            # fieldæ¨¡å¼ï¼šæ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±çš„å­—æ®µ
            if self.mode == "field":
                # è·å–é£ä¹¦è¡¨æ ¼ä¸­æ‰€æœ‰å…³è”å­—æ®µ
                link_fields = set()
                for field in bitable_fields:
                    if field.get("type") == 21:  # å…³è”ç±»å‹
                        link_fields.add(field.get("field_name"))
                
                # åˆ›å»ºç¼ºå¤±çš„å­—æ®µï¼ˆè·³è¿‡å…³è”å­—æ®µï¼‰
                for header in data_headers:
                    if header and header not in bitable_field_map and header not in link_fields:
                        print(f"âš ï¸  å‘ç°æ–°å­—æ®µ '{header}'ï¼Œåˆ›å»ºä¸­...")
                        # é»˜è®¤åˆ›å»ºæ–‡æœ¬å­—æ®µ
                        self.client.create_field(
                            self.config.app_token, 
                            self.table_id, 
                            header, 
                            "1"  # æ–‡æœ¬ç±»å‹
                        )
                        print(f"âœ… å­—æ®µ '{header}' åˆ›å»ºæˆåŠŸ")
                    elif header and header in link_fields:
                        print(f"âš ï¸  å­—æ®µ '{header}' æ˜¯å…³è”å­—æ®µï¼Œéœ€è¦æ‰‹åŠ¨é…ç½®")
                
                # åˆ·æ–°å­—æ®µåˆ—è¡¨
                bitable_fields = self.client.get_fields(self.config.app_token, self.table_id)
                bitable_field_map = {f.get("field_name"): f for f in bitable_fields}
            
            # è·å–é£ä¹¦è¡¨æ ¼ç°æœ‰è®°å½•
            existing_records = self.client.get_records(self.config.app_token, self.table_id)
            
            # æ”¶é›†ç‰¹æ®Šç±»å‹å­—æ®µä¿¡æ¯
            # type=18: æ—¥æœŸæ—¶é—´, type=21: å…³è”, type=3: å•é€‰, type=5: å¤šé€‰ç­‰
            special_field_names = set()  # éœ€è¦è·³è¿‡çš„å­—æ®µï¼ˆä¸ä¼ ç»™APIï¼‰
            single_link_fields = {}  # å•é¡¹å…³è”å­—æ®µ: field_name -> {table_id, field_name}
            
            for field in bitable_fields:
                field_type = field.get("type")
                field_name = field.get("field_name")
                field_property = field.get("property") or {}
                
                # å¦‚æœæœ‰ table_id å±æ€§ï¼Œåˆ™æ˜¯å…³è”å­—æ®µï¼ˆé£ä¹¦ API æœ‰æ—¶ type ä¸å‡†ç¡®ï¼‰
                if field_property and field_property.get("table_id"):
                    if not field_property.get("multiple"):
                        # å•é¡¹å…³è” - éœ€è¦ç‰¹æ®Šå¤„ç†
                        single_link_fields[field_name] = {
                            "table_id": field_property.get("table_id"),
                            "link_field_name": field_property.get("field_name")  # å…³è”è¡¨ä¸­çš„å­—æ®µå
                        }
                    else:
                        # å¤šé¡¹å…³è” - è·³è¿‡
                        special_field_names.add(field_name)
                elif field_type == 21:  # æ ‡å‡†å…³è”ç±»å‹
                    if field_property and (field_property.get("relation_type") == "one" or not field_property.get("multiple")):
                        single_link_fields[field_name] = field_property
                    else:
                        special_field_names.add(field_name)
                # type=18ï¼ˆæ—¥æœŸæ—¶é—´ï¼‰ä¸å†é»˜è®¤è·³è¿‡ï¼Œé£ä¹¦APIå¯èƒ½è¿”å›ä¸å‡†ç¡®çš„ç±»å‹
            
            # æ„å»ºæ•°æ®IDåˆ°è®°å½•çš„æ˜ å°„
            # æ•°æ®IDå­˜å‚¨åœ¨æŸä¸ªå­—æ®µä¸­ï¼Œå‡è®¾å­—æ®µåä¸º"æ•°æ®ID"
            def to_str(value):
                """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                if value is None:
                    return ""
                if isinstance(value, list):
                    return ",".join(str(v) for v in value)
                return str(value)
            
            record_map = {}
            for record in existing_records:
                fields = record.get("fields", {})
                data_id = fields.get("æ•°æ®ID")
                if data_id:
                    record_map[to_str(data_id)] = record
            
            # æ„å»ºå…³è”è¡¨æŸ¥æ‰¾ç¼“å­˜ {table_id: {å­—æ®µå€¼: record_id}}
            link_cache = {}
            # CSVå­—æ®µå -> å…³è”è¡¨å­—æ®µå çš„æ˜ å°„
            field_name_mapping = {
                "ä¼ä¸šç®€ç§°": "ä¼ä¸š",  # ä¼ä¸šç®€ç§° å¯¹åº” å…³è”è¡¨çš„"ä¼ä¸š"å­—æ®µ
            }
            
            if single_link_fields:
                print(f"â„¹ï¸  å‘ç° {len(single_link_fields)} ä¸ªå•é¡¹å…³è”å­—æ®µï¼Œå¼€å§‹æ„å»ºæŸ¥æ‰¾ç¼“å­˜...")
                for field_name, link_info in single_link_fields.items():
                    link_table_id = link_info.get("table_id")
                    # ä½¿ç”¨æ˜ å°„è§„åˆ™ï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹å­—æ®µå
                    link_field = field_name_mapping.get(field_name, field_name)
                    
                    if link_table_id and link_table_id not in link_cache:
                        # è·å–å…³è”è¡¨çš„æ‰€æœ‰è®°å½•
                        try:
                            link_records = self.client.get_records(self.config.app_token, link_table_id)
                            # æ„å»º {å­—æ®µå€¼: record_id} æ˜ å°„
                            link_cache[link_table_id] = {}
                            for rec in link_records:
                                rec_fields = rec.get("fields", {})
                                link_value = rec_fields.get(link_field)
                                if link_value:
                                    link_cache[link_table_id][str(link_value)] = rec.get("record_id")
                            print(f"  âœ“ å…³è”è¡¨ {link_table_id} ({link_field}): {len(link_cache[link_table_id])} æ¡è®°å½•")
                        except Exception as e:
                            print(f"  âœ— è·å–å…³è”è¡¨ {link_table_id} å¤±è´¥: {e}")
            
            # ç»Ÿè®¡
            stats = {
                "total": len(data_rows),
                "created": 0,
                "updated": 0,
                "unchanged": 0,
                "errors": 0
            }
            
            # å¤„ç†æ¯è¡Œæ•°æ®
            for i, (frozen_data, data_row) in enumerate(zip(frozen_data_list, data_rows)):
                try:
                    data_id = self._generate_data_id(frozen_data)
                    
                    # åˆå¹¶å†»ç»“åŒºåŸŸå’Œæ•°æ®åŒºåŸŸçš„æ•°æ®
                    merged_fields = {}
                    merged_fields.update(frozen_data)
                    merged_fields.update(data_row)
                    
                    # æ·»åŠ æ•°æ®ID
                    merged_fields["æ•°æ®ID"] = data_id
                    
                    # è¿‡æ»¤æ‰ç‰¹æ®Šç±»å‹å­—æ®µï¼ˆæ—¥æœŸæ—¶é—´ç­‰ï¼‰ï¼Œä¿ç•™å…³è”å­—æ®µå°è¯•å†™å…¥
                    filtered_fields = {k: v for k, v in merged_fields.items() if k not in special_field_names}
                    
                    # è½¬æ¢æ•°å­—ç±»å‹å­—æ®µ
                    for field_name, field_info in bitable_field_map.items():
                        if field_name in filtered_fields and field_info.get("type") == 2:  # æ•°å­—ç±»å‹
                            value = filtered_fields[field_name]
                            if value is not None and value != "":
                                try:
                                    filtered_fields[field_name] = float(value)
                                except (ValueError, TypeError):
                                    pass  # è½¬æ¢å¤±è´¥ä¿æŒåŸå€¼
                    
                    # å¤„ç†å•é¡¹å…³è”å­—æ®µ - å…ˆè®°å½•ä¸‹æ¥ï¼Œåé¢å†æ›´æ–°
                    link_field_values = {}
                    for field_name, link_info in single_link_fields.items():
                        # CSVä¸­çš„å­—æ®µåï¼šä¼˜å…ˆä½¿ç”¨æ˜ å°„ï¼Œå¦åˆ™ä½¿ç”¨é£ä¹¦å­—æ®µå
                        csv_field_name = field_name_mapping.get(field_name, field_name)
                        # ä»merged_fieldsä¸­è·å–æ˜¾ç¤ºå€¼
                        if csv_field_name in merged_fields:
                            link_value = str(merged_fields[csv_field_name])
                        elif field_name in merged_fields:
                            # å¦‚æœæ˜ å°„åçš„åç§°ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨åŸå§‹å­—æ®µå
                            link_value = str(merged_fields[field_name])
                        else:
                            continue
                        
                        link_table_id = link_info.get("table_id")
                        if link_table_id and link_value and link_table_id in link_cache:
                            record_id = link_cache[link_table_id].get(link_value)
                            if record_id:
                                link_field_values[field_name] = [record_id]
                                # å°è¯•ç”¨ record_id æ›´æ–°å…³è”å­—æ®µ
                                print(f"  ğŸ”— å…³è” '{csv_field_name}' -> {link_value} (record_id: {record_id})")
                            else:
                                print(f"  âš ï¸  æœªæ‰¾åˆ° '{link_value}' å¯¹åº”çš„å…³è”è®°å½•")
                    if data_id in record_map:
                        # è®°å½•å·²å­˜åœ¨
                        existing_record = record_map[data_id]
                        existing_fields = existing_record.get("fields", {})
                        
                        # ç®€å•æ¯”è¾ƒï¼ˆå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ¯”è¾ƒé€»è¾‘ï¼‰
                        def value_to_str(v):
                            """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                            if v is None:
                                return ""
                            if isinstance(v, list):
                                return ",".join(str(x) for x in v)
                            return str(v)
                        
                        needs_update = False
                        for key, value in merged_fields.items():
                            if key in existing_fields and key not in single_link_fields:
                                existing_value = existing_fields[key]
                                if value_to_str(value) != value_to_str(existing_value):
                                    needs_update = True
                                    break
                        
                        if needs_update:
                            # å…ˆæ›´æ–°éå…³è”å­—æ®µ
                            update_fields = {k: v for k, v in filtered_fields.items() if k not in single_link_fields}
                            self.client.update_record(
                                self.config.app_token,
                                self.table_id,
                                existing_record.get("record_id"),
                                update_fields
                            )
                            stats["updated"] += 1
                            print(f"ğŸ”„ æ›´æ–°è®°å½•: {data_id}")
                            
                            # å°è¯•æ›´æ–°å…³è”å­—æ®µï¼ˆå¯èƒ½æŠ¥é”™ï¼‰
                            for field_name, link_id in link_field_values.items():
                                try:
                                    self.client.update_record(
                                        self.config.app_token,
                                        self.table_id,
                                        existing_record.get("record_id"),
                                        {field_name: link_id}
                                    )
                                    print(f"  ğŸ”— å…³è” '{field_name}' -> {link_id}")
                                except Exception as e:
                                    print(f"  âš ï¸  æ›´æ–°å…³è” '{field_name}' å¤±è´¥: {e}")
                        else:
                            stats["unchanged"] += 1
                    else:
                        # æ–°å»ºè®°å½•ï¼ˆä¸å«å…³è”å­—æ®µï¼Œä½†å…ˆå°è¯•ç›´æ¥åˆ›å»ºï¼‰
                        create_fields = {k: v for k, v in filtered_fields.items() if k not in single_link_fields}
                        
                        # å¦‚æœæœ‰å…³è”å­—æ®µå€¼ï¼Œå…ˆåˆ›å»ºè®°å½•å†æ›´æ–°å…³è”å­—æ®µ
                        if link_field_values:
                            # å…ˆå°è¯•ä¸å¸¦å…³è”å­—æ®µåˆ›å»º
                            new_record = self.client.create_record(
                                self.config.app_token,
                                self.table_id,
                                create_fields
                            )
                            stats["created"] += 1
                            print(f"â• æ–°å»ºè®°å½•: {data_id}")
                            
                            # ç„¶åæ›´æ–°å…³è”å­—æ®µ
                            for field_name, link_id in link_field_values.items():
                                try:
                                    self.client.update_record(
                                        self.config.app_token,
                                        self.table_id,
                                        new_record.get("record_id"),
                                        {field_name: [link_id]}
                                    )
                                    print(f"  ğŸ”— å…³è” '{field_name}' -> {link_id}")
                                except Exception as e:
                                    print(f"  âš ï¸  æ›´æ–°å…³è” '{field_name}' å¤±è´¥: {e}")
                        else:
                            # æ— å…³è”å­—æ®µï¼Œç›´æ¥åˆ›å»º
                            new_record = self.client.create_record(
                                self.config.app_token,
                                self.table_id,
                                create_fields
                            )
                            stats["created"] += 1
                            print(f"â• æ–°å»ºæ— å…³è”å­—æ®µè®°å½•: {data_id}")
                        
                except Exception as e:
                    stats["errors"] += 1
                    print(f"âŒ å¤„ç†ç¬¬ {i+1} è¡Œå¤±è´¥: {e}")
            
            # è¾“å‡ºç»Ÿè®¡
            print(f"\nğŸ“Š åŒæ­¥å®Œæˆ:")
            print(f"   æ€»è®°å½•æ•°: {stats['total']}")
            print(f"   æ–°å»º: {stats['created']}")
            print(f"   æ›´æ–°: {stats['updated']}")
            print(f"   è·³è¿‡: {stats['unchanged']}")
            print(f"   é”™è¯¯: {stats['errors']}")
            
            return True, stats
            
        except Exception as e:
            import traceback
            print(f"âŒ åŒæ­¥å¤±è´¥: {e}")
            traceback.print_exc()
            return False, {}
