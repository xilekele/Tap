"""å‘½ä»¤æ¨¡å—"""

import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from .config import get_config
from .client import get_client
from .reader import get_reader

# è¯·æ±‚é—´éš”é…ç½®ï¼ˆç§’ï¼‰
REQUEST_INTERVAL = 0.2  # æ¯æ¬¡è¯·æ±‚é—´éš”0.2ç§’


class CheckCommand:
    """æ ¡éªŒå‘½ä»¤"""
    
    def __init__(self, file_path: str, frozen_zone: str, data_zone: str, table_id: str):
        self.file_path = Path(file_path)
        self.frozen_zone = frozen_zone
        self.data_zone = data_zone
        self.table_id = table_id
        
        self.config = get_config()
        self.client = get_client(self.config)
        self.reader = get_reader(file_path, frozen_zone, data_zone)
    
    def run(self) -> bool:
        """æ‰§è¡Œæ ¡éªŒ"""
        try:
            # æ£€æŸ¥é…ç½®
            if not self.config.is_configured():
                raise Exception("è¯·å…ˆé…ç½®APP_IDå’ŒAPP_SECRET")
            
            if not self.config.app_token:
                raise Exception("è¯·å…ˆé…ç½®app_token")
            
            # è¯»å–æ–‡ä»¶è¡¨å¤´
            file_headers = self.reader.read_headers()
            frozen_headers = self.reader.read_frozen_headers()
            
            # è·å–é£ä¹¦è¡¨æ ¼å­—æ®µ
            bitable_fields = self.client.get_fields(self.config.app_token, self.table_id)
            bitable_field_names = {f.get("field_name") for f in bitable_fields}
            
            # æ ¡éªŒæ•°æ®åŒºåŸŸå­—æ®µ
            errors = []
            for i, header in enumerate(file_headers):
                # å…¼å®¹ExcelReaderå’ŒCSVReader
                data_start = getattr(self.reader, '_data_cols', getattr(self.reader, 'data_cols', (0, 0)))[0]
                col_letter = chr(ord('A') + i + data_start)
                if header and header not in bitable_field_names:
                    errors.append({
                        "type": "field_missing",
                        "location": f"{col_letter}1",
                        "field": header,
                        "message": f"å­—æ®µ '{header}' åœ¨æ•°æ®è¡¨ä¸­ä¸å­˜åœ¨"
                    })
            
            # æ ¡éªŒå†»ç»“åŒºåŸŸå­—æ®µï¼ˆç”¨äºæ•°æ®IDï¼‰
            for header in frozen_headers:
                if header and header not in bitable_field_names:
                    errors.append({
                        "type": "field_missing",
                        "location": f"å†»ç»“åŒºåŸŸ",
                        "field": header,
                        "message": f"å†»ç»“åŒºåŸŸå­—æ®µ '{header}' åœ¨æ•°æ®è¡¨ä¸­ä¸å­˜åœ¨"
                    })
            
            if errors:
                print("âŒ æ ¡éªŒå¤±è´¥ï¼Œå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n")
                for error in errors:
                    print(f"  [{error['type']}] {error['location']}: {error['message']}")
                return False
            else:
                print("âœ… æ ¡éªŒé€šè¿‡ï¼Œæ‰€æœ‰å­—æ®µéƒ½åŒ¹é…")
                return True
                
        except Exception as e:
            print(f"âŒ æ ¡éªŒå¤±è´¥: {e}")
            return False


class FlushCommand:
    """åŒæ­¥å‘½ä»¤"""
    
    def __init__(self, file_path: str, frozen_zone: str, data_zone: str, 
                 table_id: str, mode: str = "record"):
        self.file_path = Path(file_path)
        self.frozen_zone = frozen_zone
        self.data_zone = data_zone
        self.table_id = table_id
        self.mode = mode  # "field" or "record"
        
        self.config = get_config()
        self.client = get_client(self.config)
        self.reader = get_reader(file_path, frozen_zone, data_zone)
    
    def _generate_data_id(self, frozen_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®ID
        æ•°æ®ID = ä¼ä¸šID + _ + æ•°æ®é›† + ä¼šè®¡æœŸé—´ + æŠ¥è¡¨ç±»å‹
        """
        def to_str(value):
            """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
            if value is None:
                return ""
            if isinstance(value, list):
                return ",".join(str(v) for v in value)
            return str(value)
        
        enterprise_id = to_str(frozen_data.get("ä¼ä¸šID"))
        dataset = to_str(frozen_data.get("æ•°æ®é›†"))
        period = to_str(frozen_data.get("ä¼šè®¡æœŸé—´"))
        report_type = to_str(frozen_data.get("æŠ¥è¡¨ç±»å‹"))
        
        return f"{enterprise_id}_{dataset}{period}{report_type}"
    
    def run(self) -> Tuple[bool, Dict]:
        """æ‰§è¡ŒåŒæ­¥"""
        try:
            # æ£€æŸ¥é…ç½®
            if not self.config.is_configured():
                raise Exception("è¯·å…ˆé…ç½®APP_IDå’ŒAPP_SECRET")
            
            if not self.config.app_token:
                raise Exception("è¯·å…ˆé…ç½®app_token")
            
            # è¯»å–æ–‡ä»¶æ•°æ®
            frozen_headers = self.reader.read_frozen_headers()
            data_headers = self.reader.read_headers()
            frozen_data_list = self.reader.read_frozen_data()
            data_rows = self.reader.read_data()
            
            # è·å–é£ä¹¦è¡¨æ ¼å­—æ®µ
            bitable_fields = self.client.get_fields(self.config.app_token, self.table_id)
            bitable_field_map = {f.get("field_name"): f for f in bitable_fields}
            
            # fieldæ¨¡å¼ï¼šæ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±çš„å­—æ®µ
            if self.mode == "field":
                # è·å–é£ä¹¦è¡¨æ ¼ä¸­æ‰€æœ‰å…³è”å­—æ®µ
                link_fields = set()
                for field in bitable_fields:
                    if field.get("type") == 21:  # å…³è”ç±»å‹
                        link_fields.add(field.get("field_name"))
                
                # æ”¶é›†æ‰€æœ‰ç¼ºå¤±çš„å­—æ®µï¼Œæ‰¹é‡åˆ›å»º
                missing_fields = []
                for header in data_headers:
                    if header and header not in bitable_field_map and header not in link_fields:
                        missing_fields.append({
                            "field_name": header,
                            "type": 1  # æ–‡æœ¬ç±»å‹
                        })
                    elif header and header in link_fields:
                        print(f"âš ï¸  å­—æ®µ '{header}' æ˜¯å…³è”å­—æ®µï¼Œéœ€è¦æ‰‹åŠ¨é…ç½®")
                
                # æ‰¹é‡åˆ›å»ºç¼ºå¤±çš„å­—æ®µ
                if missing_fields:
                    print(f"âš ï¸  å‘ç° {len(missing_fields)} ä¸ªæ–°å­—æ®µï¼Œæ‰¹é‡åˆ›å»ºä¸­...")
                    self.client.create_fields(
                        self.config.app_token, 
                        self.table_id, 
                        missing_fields
                    )
                    print(f"âœ… æˆåŠŸåˆ›å»º {len(missing_fields)} ä¸ªå­—æ®µ")
                
                # åˆ·æ–°å­—æ®µåˆ—è¡¨
                bitable_fields = self.client.get_fields(self.config.app_token, self.table_id)
                bitable_field_map = {f.get("field_name"): f for f in bitable_fields}
            
            # è·å–é£ä¹¦è¡¨æ ¼ç°æœ‰è®°å½•
            existing_records = self.client.get_records(self.config.app_token, self.table_id)
            time.sleep(REQUEST_INTERVAL)  # è¯·æ±‚é—´éš”
            
            # æ”¶é›†ç‰¹æ®Šç±»å‹å­—æ®µä¿¡æ¯
            # type=18: æ—¥æœŸæ—¶é—´, type=21: å…³è”, type=3: å•é€‰, type=5: å¤šé€‰ç­‰
            special_field_names = set()  # éœ€è¦è·³è¿‡çš„å­—æ®µï¼ˆä¸ä¼ ç»™APIï¼‰
            single_link_fields = {}  # å•é¡¹å…³è”å­—æ®µ: field_name -> {table_id, field_name}
            
            for field in bitable_fields:
                field_type = field.get("type")
                field_name = field.get("field_name")
                field_property = field.get("property") or {}
                
                # å¦‚æœæœ‰ table_id å±æ€§ï¼Œåˆ™æ˜¯å…³è”å­—æ®µï¼ˆé£ä¹¦ API æœ‰æ—¶ type ä¸å‡†ç¡®ï¼‰
                if field_property and field_property.get("table_id"):
                    if not field_property.get("multiple"):
                        # å•é¡¹å…³è” - éœ€è¦ç‰¹æ®Šå¤„ç†
                        single_link_fields[field_name] = {
                            "table_id": field_property.get("table_id"),
                            "link_field_name": field_property.get("field_name")  # å…³è”è¡¨ä¸­çš„å­—æ®µå
                        }
                    else:
                        # å¤šé¡¹å…³è” - è·³è¿‡
                        special_field_names.add(field_name)
                elif field_type == 21:  # æ ‡å‡†å…³è”ç±»å‹
                    if field_property and (field_property.get("relation_type") == "one" or not field_property.get("multiple")):
                        single_link_fields[field_name] = field_property
                    else:
                        special_field_names.add(field_name)
                # type=18ï¼ˆæ—¥æœŸæ—¶é—´ï¼‰ä¸å†é»˜è®¤è·³è¿‡ï¼Œé£ä¹¦APIå¯èƒ½è¿”å›ä¸å‡†ç¡®çš„ç±»å‹
            
            # æ„å»ºæ•°æ®IDåˆ°è®°å½•çš„æ˜ å°„
            # æ•°æ®IDå­˜å‚¨åœ¨æŸä¸ªå­—æ®µä¸­ï¼Œå‡è®¾å­—æ®µåä¸º"æ•°æ®ID"
            def to_str(value):
                """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                if value is None:
                    return ""
                if isinstance(value, list):
                    return ",".join(str(v) for v in value)
                return str(value)
            
            record_map = {}
            for record in existing_records:
                fields = record.get("fields", {})
                data_id = fields.get("æ•°æ®ID")
                if data_id:
                    record_map[to_str(data_id)] = record
            
            # æ„å»ºå…³è”è¡¨æŸ¥æ‰¾ç¼“å­˜ {table_id: {å­—æ®µå€¼: record_id}}
            link_cache = {}
            # CSVå­—æ®µå -> å…³è”è¡¨å­—æ®µå çš„æ˜ å°„
            field_name_mapping = {
                "ä¼ä¸šç®€ç§°": "ä¼ä¸š",  # ä¼ä¸šç®€ç§° å¯¹åº” å…³è”è¡¨çš„"ä¼ä¸š"å­—æ®µ
            }
            
            if single_link_fields:
                print(f"â„¹ï¸  å‘ç° {len(single_link_fields)} ä¸ªå•é¡¹å…³è”å­—æ®µï¼Œå¼€å§‹æ„å»ºæŸ¥æ‰¾ç¼“å­˜...")
                for field_name, link_info in single_link_fields.items():
                    link_table_id = link_info.get("table_id")
                    # ä½¿ç”¨æ˜ å°„è§„åˆ™ï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹å­—æ®µå
                    link_field = field_name_mapping.get(field_name, field_name)
                    
                    if link_table_id and link_table_id not in link_cache:
                        # è·å–å…³è”è¡¨çš„æ‰€æœ‰è®°å½•
                        try:
                            link_records = self.client.get_records(self.config.app_token, link_table_id)
                            # æ„å»º {å­—æ®µå€¼: record_id} æ˜ å°„
                            link_cache[link_table_id] = {}
                            for rec in link_records:
                                rec_fields = rec.get("fields", {})
                                link_value = rec_fields.get(link_field)
                                if link_value:
                                    link_cache[link_table_id][str(link_value)] = rec.get("record_id")
                            print(f"  âœ“ å…³è”è¡¨ {link_table_id} ({link_field}): {len(link_cache[link_table_id])} æ¡è®°å½•")
                        except Exception as e:
                            print(f"  âœ— è·å–å…³è”è¡¨ {link_table_id} å¤±è´¥: {e}")
            
            # ç»Ÿè®¡
            stats = {
                "total": len(data_rows),
                "created": 0,
                "updated": 0,
                "unchanged": 0,
                "errors": 0
            }
            
            # æ”¶é›†éœ€è¦æ‰¹é‡å¤„ç†çš„æ•°æ®
            to_create = []  # éœ€è¦æ–°å»ºçš„è®°å½• [{fields: {...}}, ...]
            to_update = []  # éœ€è¦æ›´æ–°çš„è®°å½• [{record_id: ..., fields: {...}}, ...]
            to_create_ids = []  # æ–°å»ºè®°å½•çš„æ•°æ®IDï¼Œç”¨äºåç»­å…³è”å­—æ®µæ›´æ–°
            to_update_ids = []  # æ›´æ–°è®°å½•çš„æ•°æ®IDï¼Œç”¨äºåç»­å…³è”å­—æ®µæ›´æ–°
            
            # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰éœ€è¦åˆ›å»ºå’Œæ›´æ–°çš„è®°å½•ï¼ˆä¸å«å…³è”å­—æ®µï¼‰
            for i, (frozen_data, data_row) in enumerate(zip(frozen_data_list, data_rows)):
                try:
                    data_id = self._generate_data_id(frozen_data)
                    
                    # åˆå¹¶å†»ç»“åŒºåŸŸå’Œæ•°æ®åŒºåŸŸçš„æ•°æ®
                    merged_fields = {}
                    merged_fields.update(frozen_data)
                    merged_fields.update(data_row)
                    
                    # æ·»åŠ æ•°æ®ID
                    merged_fields["æ•°æ®ID"] = data_id
                    
                    # è¿‡æ»¤æ‰ç‰¹æ®Šç±»å‹å­—æ®µï¼ˆæ—¥æœŸæ—¶é—´ç­‰ï¼‰ï¼Œä¿ç•™å…³è”å­—æ®µå°è¯•å†™å…¥
                    filtered_fields = {k: v for k, v in merged_fields.items() if k not in special_field_names}
                    
                    # è½¬æ¢æ•°å­—ç±»å‹å­—æ®µ
                    for field_name, field_info in bitable_field_map.items():
                        if field_name in filtered_fields and field_info.get("type") == 2:  # æ•°å­—ç±»å‹
                            value = filtered_fields[field_name]
                            if value is not None and value != "":
                                try:
                                    filtered_fields[field_name] = float(value)
                                except (ValueError, TypeError):
                                    pass  # è½¬æ¢å¤±è´¥ä¿æŒåŸå€¼
                    
                    # å¤„ç†å•é¡¹å…³è”å­—æ®µ - å…ˆè®°å½•ä¸‹æ¥
                    link_field_values = {}
                    for field_name, link_info in single_link_fields.items():
                        csv_field_name = field_name
                        if csv_field_name in merged_fields:
                            link_value = str(merged_fields[csv_field_name])
                        elif field_name in merged_fields:
                            link_value = str(merged_fields[field_name])
                        else:
                            continue
                        
                        link_table_id = link_info.get("table_id")
                        if link_table_id and link_value and link_table_id in link_cache:
                            record_id = link_cache[link_table_id].get(link_value)
                            if record_id:
                                link_field_values[field_name] = [record_id]
                    
                    # è¿‡æ»¤æ‰å…³è”å­—æ®µï¼ˆä¸å«åœ¨ç¬¬ä¸€æ‰¹åˆ›å»º/æ›´æ–°ä¸­ï¼‰
                    create_fields = {k: v for k, v in filtered_fields.items() if k not in single_link_fields}
                    
                    if data_id in record_map:
                        # è®°å½•å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                        existing_record = record_map[data_id]
                        existing_fields = existing_record.get("fields", {})
                        
                        def value_to_str(v):
                            """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                            if v is None:
                                return ""
                            if isinstance(v, list):
                                return ",".join(str(x) for x in v)
                            return str(v)
                        
                        needs_update = False
                        for key, value in merged_fields.items():
                            if key in existing_fields and key not in single_link_fields:
                                existing_value = existing_fields[key]
                                if value_to_str(value) != value_to_str(existing_value):
                                    needs_update = True
                                    break
                        
                        if needs_update:
                            to_update.append({
                                "record_id": existing_record.get("record_id"),
                                "fields": create_fields
                            })
                            to_update_ids.append({
                                "data_id": data_id,
                                "link_field_values": link_field_values,
                                "record_id": existing_record.get("record_id")
                            })
                        else:
                            stats["unchanged"] += 1
                    else:
                        # æ–°è®°å½•
                        to_create.append({"fields": create_fields})
                        to_create_ids.append({
                            "data_id": data_id,
                            "link_field_values": link_field_values
                        })
                        
                except Exception as e:
                    stats["errors"] += 1
                    print(f"âŒ å¤„ç†ç¬¬ {i+1} è¡Œå¤±è´¥: {e}")
            
            # æ‰¹é‡æ–°å»ºè®°å½•
            if to_create:
                # æ‰¹é‡åˆ›å»ºï¼Œæ¯æ¬¡æœ€å¤š500æ¡
                batch_size = 500
                for i in range(0, len(to_create), batch_size):
                    batch = to_create[i:i+batch_size]
                    batch_info = to_create_ids[i:i+batch_size]
                    
                    try:
                        result = self.client.create_records(
                            self.config.app_token,
                            self.table_id,
                            batch
                        )
                        # è·å–æ‰¹é‡åˆ›å»ºè¿”å›çš„ record_id åˆ—è¡¨
                        created_records = result.get("records", [])
                        created_count = len(created_records)
                        stats["created"] += created_count
                        print(f"â• æ‰¹é‡æ–°å»º {created_count} æ¡è®°å½•")
                        
                        # æ‰¹é‡æ›´æ–°å…³è”å­—æ®µï¼ˆä½¿ç”¨æ‰¹é‡åˆ›å»ºè¿”å›çš„ record_idï¼‰
                        for j, info in enumerate(batch_info):
                            if j < len(created_records) and info["link_field_values"]:
                                record_id = created_records[j].get("record_id")
                                for field_name, link_id in info["link_field_values"].items():
                                    try:
                                        self.client.update_record(
                                            self.config.app_token,
                                            self.table_id,
                                            record_id,
                                            {field_name: link_id}
                                        )
                                    except Exception as e:
                                        print(f"  âš ï¸  æ›´æ–°å…³è” '{field_name}' å¤±è´¥: {e}")
                                        
                    except Exception as e:
                        print(f"âŒ æ‰¹é‡åˆ›å»ºå¤±è´¥: {e}")
                        # å›é€€åˆ°å•æ¡åˆ›å»º
                        for j, (record, info) in enumerate(zip(batch, batch_info)):
                            try:
                                new_record = self.client.create_record(
                                    self.config.app_token,
                                    self.table_id,
                                    record["fields"]
                                )
                                stats["created"] += 1
                                print(f"â• æ–°å»ºè®°å½•: {info['data_id']}")
                                
                                # æ›´æ–°å…³è”å­—æ®µ
                                for field_name, link_id in info["link_field_values"].items():
                                    try:
                                        self.client.update_record(
                                            self.config.app_token,
                                            self.table_id,
                                            new_record.get("record_id"),
                                            {field_name: link_id}
                                        )
                                    except Exception as e:
                                        print(f"  âš ï¸  æ›´æ–°å…³è” '{field_name}' å¤±è´¥: {e}")
                            except Exception as e:
                                print(f"âŒ åˆ›å»ºè®°å½• {info['data_id']} å¤±è´¥: {e}")
            
            # æ‰¹é‡æ›´æ–°è®°å½•
            if to_update:
                # æ‰¹é‡æ›´æ–°ï¼Œæ¯æ¬¡æœ€å¤š500æ¡
                batch_size = 500
                for i in range(0, len(to_update), batch_size):
                    batch = to_update[i:i+batch_size]
                    batch_info = to_update_ids[i:i+batch_size]
                    
                    try:
                        self.client.update_records(
                            self.config.app_token,
                            self.table_id,
                            batch
                        )
                        updated_count = len(batch)
                        stats["updated"] += updated_count
                        print(f"ğŸ”„ æ‰¹é‡æ›´æ–° {updated_count} æ¡è®°å½•")
                        
                        # æ‰¹é‡æ›´æ–°å…³è”å­—æ®µ
                        for info in batch_info:
                            if info["link_field_values"]:
                                for field_name, link_id in info["link_field_values"].items():
                                    try:
                                        self.client.update_record(
                                            self.config.app_token,
                                            self.table_id,
                                            info["record_id"],
                                            {field_name: link_id}
                                        )
                                    except Exception as e:
                                        print(f"  âš ï¸  æ›´æ–°å…³è” '{field_name}' å¤±è´¥: {e}")
                                        
                    except Exception as e:
                        print(f"âŒ æ‰¹é‡æ›´æ–°å¤±è´¥: {e}")
                        # å›é€€åˆ°å•æ¡æ›´æ–°
                        for j, (record, info) in enumerate(zip(batch, batch_info)):
                            try:
                                self.client.update_record(
                                    self.config.app_token,
                                    self.table_id,
                                    record["record_id"],
                                    record["fields"]
                                )
                                stats["updated"] += 1
                                print(f"ğŸ”„ æ›´æ–°è®°å½•: {info['data_id']}")
                                
                                # æ›´æ–°å…³è”å­—æ®µ
                                for field_name, link_id in info["link_field_values"].items():
                                    try:
                                        self.client.update_record(
                                            self.config.app_token,
                                            self.table_id,
                                            info["record_id"],
                                            {field_name: link_id}
                                        )
                                    except Exception as e:
                                        print(f"  âš ï¸  æ›´æ–°å…³è” '{field_name}' å¤±è´¥: {e}")
                            except Exception as e:
                                print(f"âŒ æ›´æ–°è®°å½• {info['data_id']} å¤±è´¥: {e}")
            
            # è¾“å‡ºç»Ÿè®¡
            print(f"\nğŸ“Š åŒæ­¥å®Œæˆ:")
            print(f"   æ€»è®°å½•æ•°: {stats['total']}")
            print(f"   æ–°å»º: {stats['created']}")
            print(f"   æ›´æ–°: {stats['updated']}")
            print(f"   è·³è¿‡: {stats['unchanged']}")
            print(f"   é”™è¯¯: {stats['errors']}")
            
            return True, stats
            
        except Exception as e:
            import traceback
            print(f"âŒ åŒæ­¥å¤±è´¥: {e}")
            traceback.print_exc()
            return False, {}
